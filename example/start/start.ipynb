{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "from leaspy.main import Leaspy\n",
    "from leaspy.inputs.data.data import Data\n",
    "from leaspy.inputs.settings.algorithm_settings import AlgorithmSettings\n",
    "from leaspy.utils.output.visualization.plotter import Plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data.from_csv_file(os.path.join('_inputs', 'data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to erase the existing files in the output folder /Users/igor.koval/Documents/Work/leaspy/example/start/_outputs you provided? [y]/[n]y\n"
     ]
    }
   ],
   "source": [
    "algo_settings = AlgorithmSettings(os.path.join('_inputs', 'algorithm_settings.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaspy = Leaspy(\"multivariate\")\n",
    "leaspy.model.load_hyperparameters({'source_dimension': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing n_burn_in_iter parameter from value 100 to value 100\n",
      "Replacing n_iter parameter from value 201 to value 201\n",
      "Replacing eps parameter from value 0.001 to value 0.001\n",
      "Replacing L parameter from value 10 to value 10\n",
      "Replacing sampler_ind parameter from value HMC to value HMC\n",
      "Replacing sampler_pop parameter from value Gibbs to value Gibbs\n",
      "Replacing annealing parameter from value {'do_annealing': True, 'initial_temperature': 300, 'n_plateau': 10, 'n_iter': 200} to value {'do_annealing': True, 'initial_temperature': 300, 'n_plateau': 10, 'n_iter': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igor.koval/Documents/Work/leaspy/example/start/../../leaspy/algo/samplers/abstract_sampler.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  accepted = torch.tensor(1. * (torch.rand(alpha.size(0)) < alpha), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ALGO ===\n",
      "Instance of MCMC_SAEM (tensor) algo \n",
      "Iteration 0\n",
      "=Samplers \n",
      "    g rate : 4.0%, std: 0.005\n",
      "    v0 rate : 8.0%, std: 0.005\n",
      "    tau rate : 3.4193548387096775%, std: 0.1\n",
      "    xi rate : 3.82258064516129%, std: 0.1\n",
      "    sources rate : 3.9838709677419355%, std: 0.1\n",
      "    betas rate : 20.0%, std: 0.005\n",
      "Annealing \n",
      "Temperature : 270.0\n",
      "=== MODEL ===\n",
      "g : tensor([ 0.3350, -0.0649,  0.0916,  0.0302])\n",
      "betas : tensor([[ 0.0025,  0.0000],\n",
      "        [ 0.0071,  0.0049],\n",
      "        [-0.0035, -0.0011]])\n",
      "tau_mean : 75.9718246459961\n",
      "tau_std : 0.9745923280715942\n",
      "xi_mean : 0.0\n",
      "xi_std : 0.050175175070762634\n",
      "sources_mean : 0.0\n",
      "sources_std : 1.0\n",
      "noise_std : 0.5967006683349609\n",
      "v0 : tensor([0.0078, 0.0016, 0.0031, 0.0093])\n",
      "\n",
      "Duration since last print : 1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/plotting/_core.py:998: UserWarning: Attempting to set identical left==right results\n",
      "in singular transformations; automatically expanding.\n",
      "left=0.0, right=0.0\n",
      "  ax.set_xlim(left, right)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ALGO ===\n",
      "Instance of MCMC_SAEM (tensor) algo \n",
      "Iteration 50\n",
      "=Samplers \n",
      "    g rate : 92.0%, std: 0.010717944050000006\n",
      "    v0 rate : 88.0%, std: 0.010717944050000006\n",
      "    tau rate : 96.7096745967865%, std: 0.1\n",
      "    xi rate : 99.87096786499023%, std: 0.1\n",
      "    sources rate : 99.40322637557983%, std: 0.1\n",
      "    betas rate : 100.0%, std: 0.015692141883605012\n",
      "Annealing \n",
      "Temperature : 210.0\n",
      "=== MODEL ===\n",
      "g : tensor([0.2533, 0.0604, 0.1370, 0.0388])\n",
      "betas : tensor([[-0.1321,  0.0356],\n",
      "        [ 0.0486,  0.0458],\n",
      "        [ 0.0111, -0.0214]])\n",
      "tau_mean : 76.07306671142578\n",
      "tau_std : 1.170271396636963\n",
      "xi_mean : 0.0\n",
      "xi_std : 0.08431924134492874\n",
      "sources_mean : 0.0\n",
      "sources_std : 1.0\n",
      "noise_std : 0.582001268863678\n",
      "v0 : tensor([-0.0269, -0.0528, -0.0575,  0.0733])\n",
      "\n",
      "Duration since last print : 7.0s\n",
      "=== ALGO ===\n",
      "Instance of MCMC_SAEM (tensor) algo \n",
      "Iteration 100\n",
      "=Samplers \n",
      "    g rate : 80.0%, std: 0.022974864931786104\n",
      "    v0 rate : 64.0%, std: 0.022974864931786104\n",
      "    tau rate : 97.20968008041382%, std: 0.1\n",
      "    xi rate : 99.85483884811401%, std: 0.1\n",
      "    sources rate : 99.54838752746582%, std: 0.1\n",
      "    betas rate : 88.0%, std: 0.049248663379038146\n",
      "Annealing \n",
      "Temperature : 120.0\n",
      "=== MODEL ===\n",
      "g : tensor([ 0.2352, -0.0369,  0.3896,  0.1463])\n",
      "betas : tensor([[0.1100, 0.3256],\n",
      "        [0.3002, 0.4602],\n",
      "        [0.1126, 0.0392]])\n",
      "tau_mean : 76.22489929199219\n",
      "tau_std : 1.4352904558181763\n",
      "xi_mean : 0.0\n",
      "xi_std : 0.113370381295681\n",
      "sources_mean : 0.0\n",
      "sources_std : 1.0\n",
      "noise_std : 0.5671220421791077\n",
      "v0 : tensor([-0.2123, -0.2031, -0.5077, -0.1463])\n",
      "\n",
      "Duration since last print : 5.0s\n",
      "=== ALGO ===\n",
      "Instance of MCMC_SAEM (tensor) algo \n",
      "Iteration 150\n",
      "=Samplers \n",
      "    g rate : 60.0%, std: 0.049248663379038146\n",
      "    v0 rate : 84.0%, std: 0.049248663379038146\n",
      "    tau rate : 97.48387336730957%, std: 0.1\n",
      "    xi rate : 99.48387145996094%, std: 0.1\n",
      "    sources rate : 99.4516134262085%, std: 0.1\n",
      "    betas rate : 40.0%, std: 0.15456340266435378\n",
      "Annealing \n",
      "Temperature : 60.0\n",
      "=== MODEL ===\n",
      "g : tensor([0.1109, 0.1923, 0.3800, 0.1171])\n",
      "betas : tensor([[0.2336, 0.6135],\n",
      "        [0.3911, 0.5548],\n",
      "        [0.1576, 0.1448]])\n",
      "tau_mean : 76.25135803222656\n",
      "tau_std : 1.545374870300293\n",
      "xi_mean : 0.0\n",
      "xi_std : 0.1193145141005516\n",
      "sources_mean : 0.0\n",
      "sources_std : 1.0\n",
      "noise_std : 0.5601488947868347\n",
      "v0 : tensor([-0.2688, -0.3420, -0.6694, -0.3987])\n",
      "\n",
      "Duration since last print : 7.0s\n",
      "=== ALGO ===\n",
      "Instance of MCMC_SAEM (tensor) algo \n",
      "Iteration 200\n",
      "=Samplers \n",
      "    g rate : 16.0%, std: 0.06424552653544555\n",
      "    v0 rate : 8.0%, std: 0.07138391837271728\n",
      "    tau rate : 96.37096524238586%, std: 0.1\n",
      "    xi rate : 97.83871173858643%, std: 0.1\n",
      "    sources rate : 99.29032325744629%, std: 0.1\n",
      "    betas rate : 8.0%, std: 0.11154995333689079\n",
      "Annealing \n",
      "Temperature : 1\n",
      "=== MODEL ===\n",
      "g : tensor([0.0990, 0.2310, 0.3895, 0.1239])\n",
      "betas : tensor([[0.2412, 0.6390],\n",
      "        [0.3988, 0.6013],\n",
      "        [0.1394, 0.1548]])\n",
      "tau_mean : 76.29977416992188\n",
      "tau_std : 1.644712209701538\n",
      "xi_mean : 0.0\n",
      "xi_std : 0.1272154152393341\n",
      "sources_mean : 0.0\n",
      "sources_std : 1.0\n",
      "noise_std : 0.554114818572998\n",
      "v0 : tensor([-0.3142, -0.3989, -0.8635, -0.4649])\n",
      "\n",
      "Duration since last print : 5.0s\n"
     ]
    }
   ],
   "source": [
    "leaspy.fit(data, algorithm_settings=algo_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_convergence_model_parameters() missing 4 required positional arguments: 'path', 'path_saveplot_1', 'path_saveplot_2', and 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-08992a2b2c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplotter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_convergence_model_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: plot_convergence_model_parameters() missing 4 required positional arguments: 'path', 'path_saveplot_1', 'path_saveplot_2', and 'model'"
     ]
    }
   ],
   "source": [
    "plotter = Plotter()\n",
    "plotter.plot_convergence_model_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
